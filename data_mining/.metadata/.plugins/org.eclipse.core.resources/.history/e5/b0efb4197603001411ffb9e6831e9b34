import weka.core.Instance;
import weka.core.Instances;
import weka.core.converters.ArffLoader;
import weka.classifiers.Evaluation;
import weka.classifiers.bayes.NaiveBayesUpdateable;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.bayes.NaiveBayes;
import weka.filters.unsupervised.attribute.StringToWordVector;

import java.io.File;
import java.io.FileReader;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.util.Random;

/**
 * This example trains NaiveBayes incrementally on data obtained
 * from the ArffLoader.
 *
 * @author FracPete (fracpete at waikato dot ac dot nz)
 */
public class IncrementalClassifier {

  /**
   * Expects an ARFF file as first argument (class attribute is assumed
   * to be the last attribute).
   *
   * @param args        the commandline arguments
   * @throws Exception  if something goes wrong
   */
  public static void main(String[] args) throws Exception {
    // load data
//    ArffLoader loader = new ArffLoader();
//    loader.setFile(new File("/home/jeremy/taxonomic-classification/create_db/Alveolata__33630/learn/learning_S50.arff"));
	  
	  BufferedReader breader = new BufferedReader(new FileReader("/home/jeremy/taxonomic-classification/create_db/Alveolata__33630/learn/learning_S50.arff"));
	  System.out.println("TOTO");
	  Instances train = new Instances (breader);
	  train.setClassIndex(train.numAttributes()-1);
	  
	  breader.close();
	  
	  NaiveBayes nb = new NaiveBayes();
	  nb.buildClassifier(train);
	  Evaluation eval = new Evaluation(train);
	  eval.crossValidateModel(nb, train, 10, new Random(1));
	  System.out.println(eval.toSummaryString("\nResults\n=======", true));
	  System.out.println(eval.fMeasure(1) + eval.precision(1) + eval.recall(1));
    
    

  }
}