import weka.core.Instance;
import weka.core.Instances;
import weka.core.converters.ArffLoader;
import weka.classifiers.Evaluation;
import weka.classifiers.bayes.NaiveBayesUpdateable;

import java.io.File;
import java.io.FileReader;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.util.Random;

/**
 * This example trains NaiveBayes incrementally on data obtained
 * from the ArffLoader.
 *
 * @author FracPete (fracpete at waikato dot ac dot nz)
 */
public class IncrementalClassifier {

  /**
   * Expects an ARFF file as first argument (class attribute is assumed
   * to be the last attribute).
   *
   * @param args        the commandline arguments
   * @throws Exception  if something goes wrong
   */
  public static void main(String[] args) throws Exception {
    // load data
    ArffLoader loader = new ArffLoader();
    loader.setFile(new File("/home/jeremy/taxonomic-classification/create_db/Alveolata__33630/learn/learning_S50.arff"));
    Instances structure = loader.getStructure();
    structure.setClassIndex(structure.numAttributes() - 1);

    // train NaiveBayes
    NaiveBayesUpdateable nb = new NaiveBayesUpdateable();
    nb.buildClassifier(structure);
    Instance current;
    int cpt = 0;
    while ((current = loader.getNextInstance(structure)) != null)
    {
    	System.out.println("cpt = "+cpt);
      nb.updateClassifier(current);
      cpt++;
    }

    System.out.println(nb);
    
    Evaluation eval = new Evaluation(structure);
    eval.crossValidateModel(nb,structure,10);
    
    Evaluation eval = new Evaluation(structure);
    eval.evaluateModel(nb, structure);
    System.out.println(eval.toSummaryString("\nResults\n======\n", false));
  }
}